{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "q91r1Oy2pbe3",
        "RpqHEqli6aVk",
        "p5aGATGx6svt",
        "oakAh4ZF_E-8"
      ],
      "gpuType": "T4",
      "mount_file_id": "1P0AU2iLVGGE0G7XZvOagjvvxv6fyt-_8",
      "authorship_tag": "ABX9TyOEmflP2oit1TYRxHp64TcN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GreeneryScenery/SegmentPlants/blob/main/scripts/Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "PLpU_TkvTn7q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Settings"
      ],
      "metadata": {
        "id": "TLwC6f83pZup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Settings\n",
        "WRITE : bool = True # @param {type:'boolean'}\n",
        "READ : bool = True # @param {type:'boolean'}\n",
        "CONTINUE : bool = False # @param {type:'boolean'}\n",
        "WRITE_IMAGE : bool = True # @param {type:'boolean'}\n",
        "READ_IMAGE : bool = True  # @param {type:'boolean'}\n",
        "SAVE : bool = True # @param {type:'boolean'}\n",
        "PATH : str = '/content/SegmentPlants/inputs/8/aligned' # @param {type:'string'}\n",
        "DATES_PATH : str = 'SegmentPlants/inputs/8/dates.csv' # @param {type:'string'}\n",
        "READ_PATH : str = '' # @param {type:'string'}\n",
        "CONTINUE_PATH : str = '' # @param {type:'string'}\n",
        "CLASSES : list[str] = ['mango', 'romaine lettuce', 'tomato'] # @param {type:'raw'}\n",
        "INDEX_TO_CLASS : dict[int, str] = {0: 'mango', 1: 'romaine', 2: 'tomato'} # @param {type:'raw'}\n",
        "INDEX_TO_SUBCLASS : dict[int, str] = {0: 'growing', 1: 'harvest', 2: 'ripe', 3: 'unripe'} # @param {type:'raw'}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Ym6O5g-TUBSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading"
      ],
      "metadata": {
        "id": "q91r1Oy2pbe3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5xFG-lCjkLP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image, ImageOps\n",
        "import cv2\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.ops import box_convert\n",
        "import shutil\n",
        "from copy import deepcopy\n",
        "from shapely import geometry\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7g7-ZAI2jkrK"
      },
      "outputs": [],
      "source": [
        "!pip install supervision==0.16.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import supervision as sv"
      ],
      "metadata": {
        "id": "8hWYLLuFI7FQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install neuralforecast"
      ],
      "metadata": {
        "id": "gq4M8U66pasq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from neuralforecast import NeuralForecast\n",
        "from neuralforecast.models import Autoformer\n",
        "from neuralforecast.losses.pytorch import MAE"
      ],
      "metadata": {
        "id": "Oz3X0Jevpc4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/GreeneryScenery/SegmentPlants.git"
      ],
      "metadata": {
        "id": "weiXui8w2gYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHyYcE6Dzg5h"
      },
      "outputs": [],
      "source": [
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "colours = {\n",
        "    'dark blue': '#2861ae',\n",
        "    'light blue': '#add8f6',\n",
        "    'purple': '#c68bdd',\n",
        "    'pink': '#f9c7e2',\n",
        "    'yellow': '#f6e9ad',\n",
        "    'dark green': '#28ae8b'\n",
        "}\n",
        "colour_palette = sv.ColorPalette.from_hex(colours.values())\n",
        "box_annotator = sv.BoxAnnotator(color = colour_palette, thickness = 2, text_scale = 0.6, text_thickness = 1)\n",
        "mask_annotator = sv.MaskAnnotator(color = colour_palette, opacity = 0.65)"
      ],
      "metadata": {
        "id": "DT0DaKDzJfqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKlRj2BGjxhT"
      },
      "outputs": [],
      "source": [
        "if WRITE:\n",
        "  '''\n",
        "  Setup Grounding DINO\n",
        "  '''\n",
        "\n",
        "  from huggingface_hub import hf_hub_download\n",
        "\n",
        "  !git clone https://github.com/open-mmlab/mmdetection.git\n",
        "\n",
        "  !pip install -r mmdetection/requirements/multimodal.txt\n",
        "\n",
        "  !pip install -U openmim\n",
        "  !mim install mmengine mmdet mmcv\n",
        "\n",
        "  from transformers import BertConfig, BertModel\n",
        "  from transformers import AutoTokenizer\n",
        "\n",
        "  config = BertConfig.from_pretrained('bert-base-uncased')\n",
        "  model = BertModel.from_pretrained('bert-base-uncased', add_pooling_layer = False, config = config)\n",
        "  tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "  config.save_pretrained('mmdetection/bert-base-uncased')\n",
        "  model.save_pretrained('mmdetection/bert-base-uncased')\n",
        "  tokenizer.save_pretrained('mmdetection/bert-base-uncased')\n",
        "\n",
        "  shutil.move('SegmentPlants/inputs/data/detection/config/config.py', 'mmdetection/configs/grounding_dino/config.py')\n",
        "\n",
        "  hf_hub_download(repo_id = 'GreeneryScenery/Chronocrop', filename = 'detection_model.pth', local_dir = 'SegmentPlants/models')\n",
        "\n",
        "  '''\n",
        "  Setup SAM\n",
        "  '''\n",
        "\n",
        "  !{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n",
        "\n",
        "  !wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n",
        "\n",
        "  sys.path.append('..')\n",
        "  from segment_anything import sam_model_registry, SamPredictor\n",
        "\n",
        "  sam_checkpoint = 'sam_vit_h_4b8939.pth'\n",
        "  model_type = 'vit_h'\n",
        "\n",
        "  sam = sam_model_registry[model_type](checkpoint = sam_checkpoint)\n",
        "  sam.to(device = DEVICE)\n",
        "\n",
        "  predictor = SamPredictor(sam)\n",
        "\n",
        "  '''\n",
        "  Setup Filter\n",
        "  '''\n",
        "\n",
        "  def in_box(current_box, compare_box, threshold = 0.85) -> bool:\n",
        "    current_x_min, current_y_min, current_x_max, current_y_max = current_box\n",
        "    compare_x_min, compare_y_min, compare_x_max, compare_y_max = compare_box\n",
        "\n",
        "    overlap_x_min = max(current_x_min, compare_x_min)\n",
        "    overlap_y_min = max(current_y_min, compare_y_min)\n",
        "    overlap_x_max = min(current_x_max, compare_x_max)\n",
        "    overlap_y_max = min(current_y_max, compare_y_max)\n",
        "\n",
        "    overlap_width = max(0, overlap_x_max - overlap_x_min)\n",
        "    overlap_height = max(0, overlap_y_max - overlap_y_min)\n",
        "\n",
        "    overlap_area = overlap_width * overlap_height\n",
        "\n",
        "    smaller_box_area = (compare_x_max - compare_x_min) * (compare_y_max - compare_y_min)\n",
        "\n",
        "    if overlap_area / smaller_box_area >= threshold:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "if READ:\n",
        "  '''\n",
        "  Setup DINOv2 Image Classification\n",
        "  '''\n",
        "\n",
        "  hf_hub_download(repo_id = 'GreeneryScenery/Chronocrop', filename = 'subclassification_model.pt', local_dir = 'SegmentPlants/models')\n",
        "\n",
        "  from SegmentPlants.scripts.model import Classifier\n",
        "\n",
        "  classification_model = Classifier(len(INDEX_TO_CLASS), len(INDEX_TO_SUBCLASS))\n",
        "  classification_model.load_state_dict(torch.load('SegmentPlants/models/subclassification_model.pt'))\n",
        "  classification_model.eval()\n",
        "  classification_model.to(DEVICE)\n",
        "\n",
        "  transform = transforms.Compose([\n",
        "      transforms.RandomResizedCrop(224),\n",
        "      transforms.RandomHorizontalFlip(),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "  ])\n",
        "\n",
        "  def preprocess(img):\n",
        "      img = transform(img)\n",
        "      img = img[None, :]\n",
        "      return img"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_image(image : np.ndarray, expected_size : int) -> np.ndarray:\n",
        "    height = image.shape[0]\n",
        "    width = image.shape[1]\n",
        "    new_width = expected_size\n",
        "    new_height = expected_size\n",
        "\n",
        "    if width > height:\n",
        "        ratio = new_width / width\n",
        "        new_height = int(height * ratio)\n",
        "    else:\n",
        "        ratio = new_height / height\n",
        "        new_width = int(width * ratio)\n",
        "\n",
        "    new_dimensions = (new_width, new_height)\n",
        "    if ratio < 1:\n",
        "        interpolation = cv2.INTER_AREA\n",
        "    else:\n",
        "        interpolation = cv2.INTER_CUBIC\n",
        "    new_image = cv2.resize(image, new_dimensions, interpolation = interpolation)\n",
        "    return new_image"
      ],
      "metadata": {
        "id": "SEi-PMGlbrxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_padding(image : Image.Image, expected_size : tuple[int, int]) -> tuple[Image.Image, tuple[int, int]]:\n",
        "    '''\n",
        "    Add padding around image while repositioning a coordinate.\n",
        "\n",
        "    :param image: PIL Image.\n",
        "    :param expected_size: Expected size of new image in pixels.\n",
        "    :param roi: Region of interest (coordinate) to reposition.\n",
        "    :returns: A tuple of the padded image and repositioned roi.\n",
        "    '''\n",
        "\n",
        "    delta_width : int = expected_size[0] - image.size[0]\n",
        "    delta_height : int = expected_size[1] - image.size[1]\n",
        "    padding_width : int = delta_width // 2\n",
        "    padding_height : int = delta_height // 2\n",
        "    padding : tuple[int, int, int, int] = (padding_width, padding_height, delta_width - padding_width, delta_height - padding_height)\n",
        "    new_image : Image.Image = ImageOps.expand(image, padding)\n",
        "    return new_image"
      ],
      "metadata": {
        "id": "hzKvzJgnf1b9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading Images"
      ],
      "metadata": {
        "id": "RpqHEqli6aVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_names = []\n",
        "\n",
        "for image_name in os.listdir(PATH):\n",
        "  image_names.append(image_name)\n",
        "\n",
        "image_names = [str(i) + '.jpg' for i in sorted([int(num.split('.')[0]) for num in image_names])]"
      ],
      "metadata": {
        "id": "Ci3MDDwF3jJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.rmtree('processed', ignore_errors = True)"
      ],
      "metadata": {
        "id": "xLPFFBTrx3mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7ubKJJl3M3O"
      },
      "outputs": [],
      "source": [
        "os.makedirs('processed', exist_ok = True)\n",
        "\n",
        "image_paths = []\n",
        "\n",
        "for image_name in image_names:\n",
        "  image = Image.open(os.path.join(PATH, image_name))\n",
        "  image = Image.fromarray(resize_image(np.array(ImageOps.exif_transpose(image)), 1500))\n",
        "  image_path = f'processed/{image_name.split('.')[0]}.png'\n",
        "  image.save(image_path)\n",
        "  image_paths.append(image_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('outputs', exist_ok = True)\n",
        "\n",
        "if WRITE and WRITE_IMAGE:\n",
        "  os.makedirs('outputs/grounding_dino', exist_ok = True)\n",
        "  os.makedirs('outputs/sam', exist_ok = True)\n",
        "  os.makedirs('outputs/filter', exist_ok = True)\n",
        "\n",
        "if READ and READ_IMAGE:\n",
        "  os.makedirs('outputs/stage', exist_ok = True)\n",
        "  os.makedirs('outputs/classes', exist_ok = True)\n",
        "  os.makedirs('outputs/growth', exist_ok = True)"
      ],
      "metadata": {
        "id": "RKaTWPQS7b1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Writing"
      ],
      "metadata": {
        "id": "p5aGATGx6svt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if WRITE:\n",
        "  final_xyxy = []\n",
        "  final_masks = []\n",
        "  final_labels = []\n",
        "  final_polygons = []"
      ],
      "metadata": {
        "id": "YLlhqopKLFcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if WRITE:\n",
        "  for count, image_path in enumerate(image_paths):\n",
        "    print(f'Writing {count + 1} out of {len(image_paths)}.')\n",
        "\n",
        "    output_name = image_path.split('/')[-1].split('.')[0]\n",
        "\n",
        "    image_source_bgr = cv2.imread(image_path)\n",
        "    image_source = cv2.cvtColor(image_source_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    '''\n",
        "    Grounding DINO\n",
        "    '''\n",
        "\n",
        "    TEXT_PROMPT = ' . '.join(CLASSES)\n",
        "    TEXT_PROMPT = f'\"{TEXT_PROMPT}\"'\n",
        "\n",
        "    !python mmdetection/demo/image_demo.py $image_path mmdetection/configs/grounding_dino/config.py --weights SegmentPlants/models/detection_model.pth --texts $TEXT_PROMPT --device $DEVICE\n",
        "\n",
        "    with open(f'outputs/preds/{output_name}.json') as json_file:\n",
        "      data = json.load(json_file)\n",
        "\n",
        "    labels = np.array(data['labels'])\n",
        "    scores = np.array(data['scores'])\n",
        "    xyxy_grounding_dino = np.array(data['bboxes'])\n",
        "\n",
        "    shutil.rmtree('outputs/preds')\n",
        "    shutil.rmtree('outputs/vis')\n",
        "\n",
        "    labels = np.take(np.array(CLASSES), labels).astype(str)\n",
        "\n",
        "    boolean = scores > 0.3\n",
        "\n",
        "    if sum(boolean) == 0:\n",
        "      if WRITE_IMAGE:\n",
        "        original_image = Image.fromarray(image_source)\n",
        "        original_image.save(f'outputs/grounding_dino/{output_name}.png')\n",
        "        original_image.save(f'outputs/sam/{output_name}.png')\n",
        "        original_image.save(f'outputs/filter/{output_name}.png')\n",
        "\n",
        "      final_polygons.append(None)\n",
        "      final_xyxy.append(None)\n",
        "      final_masks.append(None)\n",
        "      final_labels.append(None)\n",
        "      continue\n",
        "\n",
        "    scores = scores[boolean]\n",
        "    labels = labels[boolean]\n",
        "    xyxy_grounding_dino = xyxy_grounding_dino[boolean]\n",
        "\n",
        "    detections_grounding_dino = sv.Detections(xyxy=xyxy_grounding_dino)\n",
        "\n",
        "    labels_grounding_dino = [\n",
        "        f'{label} {score:.2f}'\n",
        "        for label, score\n",
        "        in zip(labels, scores)\n",
        "    ]\n",
        "\n",
        "    if WRITE_IMAGE:\n",
        "      annotated_grounding_dino = image_source_bgr.copy()\n",
        "      annotated_grounding_dino = box_annotator.annotate(scene = annotated_grounding_dino, detections = detections_grounding_dino, labels = labels_grounding_dino)\n",
        "\n",
        "      grounding_dino_image = Image.fromarray(cv2.cvtColor(annotated_grounding_dino, cv2.COLOR_BGR2RGB))\n",
        "      grounding_dino_image.save(f'outputs/grounding_dino/{output_name}.png')\n",
        "\n",
        "    '''\n",
        "    SAM\n",
        "    '''\n",
        "\n",
        "    predictor.set_image(image_source)\n",
        "\n",
        "    transformed_boxes = predictor.transform.apply_boxes_torch(torch.from_numpy(xyxy_grounding_dino), image_source.shape[:2])\n",
        "\n",
        "    centres_x = (transformed_boxes[:, 0] + transformed_boxes[:, 2]) // 2\n",
        "    centres_y = (transformed_boxes[:, 1] + transformed_boxes[:, 3]) // 2\n",
        "\n",
        "    centres = torch.stack((centres_x, centres_y), dim = 1).to(torch.int)\n",
        "\n",
        "    masks, iou_predictions, low_res_masks = predictor.predict_torch(\n",
        "        point_coords = centres.unsqueeze(1).to(DEVICE),\n",
        "        point_labels = torch.from_numpy(np.full(len(transformed_boxes), 1, dtype = int)).unsqueeze(1).to(DEVICE),\n",
        "        boxes = transformed_boxes.to(DEVICE),\n",
        "        multimask_output = False,\n",
        "    )\n",
        "\n",
        "    if DEVICE == 'cpu':\n",
        "      detections_sam = sv.Detections(\n",
        "          xyxy = sv.mask_to_xyxy(masks = masks.numpy()[:, 0, :, :]),\n",
        "          mask = masks.numpy()[:, 0, :, :],\n",
        "          confidence = iou_predictions.numpy()[:, 0],\n",
        "          class_id = np.array(labels_grounding_dino)\n",
        "      )\n",
        "    else:\n",
        "      detections_sam = sv.Detections(\n",
        "          xyxy = sv.mask_to_xyxy(masks = masks.cpu().numpy()[:, 0, :, :]),\n",
        "          mask = masks.cpu().numpy()[:, 0, :, :],\n",
        "          confidence = iou_predictions.cpu().numpy()[:, 0],\n",
        "          class_id = np.array(labels_grounding_dino)\n",
        "      )\n",
        "\n",
        "    detections_sam = detections_sam.with_nms(threshold = 0.5, class_agnostic = True)\n",
        "    masks_sam = detections_sam.mask\n",
        "    xyxy_sam = detections_sam.xyxy\n",
        "    labels_sam = detections_sam.class_id\n",
        "    class_id_sam = np.arange(len(labels_sam))\n",
        "    np.random.shuffle(class_id_sam)\n",
        "\n",
        "    detections_sam = sv.Detections(xyxy = xyxy_sam, mask = masks_sam, class_id = class_id_sam)\n",
        "\n",
        "    if WRITE_IMAGE:\n",
        "      annotated_sam = mask_annotator.annotate(scene = image_source_bgr.copy(), detections = detections_sam)\n",
        "      combined_sam = box_annotator.annotate(scene = annotated_sam, detections = detections_sam, labels = labels_sam)\n",
        "      Image.fromarray(cv2.cvtColor(combined_sam, cv2.COLOR_BGR2RGB)).save(f'outputs/sam/{output_name}.png')\n",
        "\n",
        "    predictor.reset_image()\n",
        "\n",
        "    '''\n",
        "    Filter\n",
        "    '''\n",
        "\n",
        "    masks_filter = detections_sam.mask\n",
        "    xyxy_filter = detections_sam.xyxy\n",
        "    labels_filter = labels_sam.copy()\n",
        "    polygons_filter = []\n",
        "\n",
        "    filter = []\n",
        "\n",
        "    for i in range(len(xyxy_filter)):\n",
        "      for j in range(len(xyxy_filter)):\n",
        "        if j != i:\n",
        "          if in_box(xyxy_filter[i], xyxy_filter[j]):\n",
        "            filter.append(i)\n",
        "            break\n",
        "\n",
        "    for i in sorted(filter, reverse = True):\n",
        "      masks_filter = np.delete(masks_filter, i, axis = 0)\n",
        "      xyxy_filter = np.delete(xyxy_filter, i, axis = 0)\n",
        "      labels_filter = np.delete(labels_filter, i, axis = 0)\n",
        "\n",
        "    class_id_filter = np.arange(len(labels_filter))\n",
        "    np.random.shuffle(class_id_filter)\n",
        "\n",
        "    detections_filter = sv.Detections(\n",
        "        xyxy = xyxy_filter,\n",
        "        mask = masks_filter,\n",
        "        class_id = class_id_filter\n",
        "    )\n",
        "\n",
        "    if WRITE_IMAGE:\n",
        "      annotated_filter = mask_annotator.annotate(scene = image_source_bgr.copy(), detections = detections_filter)\n",
        "      combined_filter = box_annotator.annotate(scene = annotated_filter, detections = detections_filter, labels = labels_filter)\n",
        "      Image.fromarray(cv2.cvtColor(combined_filter, cv2.COLOR_BGR2RGB)).save(f'outputs/filter/{output_name}.png')\n",
        "\n",
        "    for mask in masks_filter:\n",
        "      polygons = sv.mask_to_polygons(mask)\n",
        "      for p in enumerate(polygons):\n",
        "        polygons[p[0]] = p[1].tolist()\n",
        "      polygons_filter.append(polygons[sorted([(c,len(l)) for c,l in enumerate(polygons)], key = lambda t: t[1])[-1][0]])\n",
        "    final_polygons.append(polygons_filter)\n",
        "\n",
        "    final_xyxy.append(xyxy_filter.tolist())\n",
        "    final_masks.append(masks_filter)\n",
        "    final_labels.append(labels_filter.tolist())"
      ],
      "metadata": {
        "id": "3won0b5f6VtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "write_outputs = {\n",
        "    'xyxy': final_xyxy,\n",
        "    'polygons': final_polygons,\n",
        "    'labels': final_labels\n",
        "}"
      ],
      "metadata": {
        "id": "dNrrBDp9qdPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if WRITE and SAVE:\n",
        "  with open('write_outputs.json', mode = 'w') as f:\n",
        "      json.dump(write_outputs, f)"
      ],
      "metadata": {
        "id": "yDM3agC9sgdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if WRITE and WRITE_IMAGE and SAVE:\n",
        "  !zip -r outputs.zip outputs"
      ],
      "metadata": {
        "id": "r5H3c0_uDFyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading"
      ],
      "metadata": {
        "id": "rW2zx7sHRuB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if READ:\n",
        "  if WRITE:\n",
        "    with open('write_outputs.json') as json_file:\n",
        "      write_outputs = json.load(json_file)\n",
        "  else:\n",
        "    with open(READ_PATH) as json_file:\n",
        "      write_outputs = json.load(json_file)\n",
        "\n",
        "  read_xyxy = write_outputs['xyxy']\n",
        "  read_polygons = write_outputs['polygons']\n",
        "  read_labels = write_outputs['labels']\n",
        "\n",
        "  if CONTINUE:\n",
        "    with open(CONTINUE_PATH) as json_file:\n",
        "      read_outputs = json.load(json_file)\n",
        "    centres = read_outputs['centres']\n",
        "    areas = read_outputs['areas']\n",
        "    forecasts = read_outputs['forecasts']\n",
        "  else:\n",
        "    centres = dict()\n",
        "    areas = dict()\n",
        "    forecasts = dict()"
      ],
      "metadata": {
        "id": "-CiM4PjbNqNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dates = pd.read_csv(DATES_PATH)"
      ],
      "metadata": {
        "id": "Blk7Gl5Up7Cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if READ:\n",
        "  for i, image_path in enumerate(image_paths):\n",
        "    print(f'Reading {i + 1} out of {len(image_paths)}.')\n",
        "\n",
        "    output_name = image_path.split('/')[-1].split('.')[0]\n",
        "\n",
        "    image = cv2.imread(image_path)\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    for key in areas:\n",
        "      areas[key].append(None)\n",
        "      forecasts[key].append(None)\n",
        "\n",
        "    if read_xyxy[i] is not None and read_polygons[i] is not None:\n",
        "      labels_stage = []\n",
        "      class_id_stage = []\n",
        "\n",
        "      labels_classes = []\n",
        "      class_id_classes = []\n",
        "      custom_colour_lookup_classes = []\n",
        "\n",
        "      xyxy_final = []\n",
        "      masks_dinov2 = []\n",
        "      masks_sam = []\n",
        "\n",
        "      labels_growth = []\n",
        "      class_id_growth = []\n",
        "\n",
        "      for j in range(len(read_xyxy[i])):\n",
        "        masked_image = image_rgb.copy()\n",
        "        bbox = read_xyxy[i][j]\n",
        "        masked_image = masked_image[bbox[1] : bbox[3], bbox[0] : bbox[2]]\n",
        "\n",
        "        '''\n",
        "        Subclassification\n",
        "        '''\n",
        "\n",
        "        img = preprocess(Image.fromarray(masked_image))\n",
        "        img = img.to(DEVICE)\n",
        "        with torch.no_grad():\n",
        "            result = classification_model(img)\n",
        "        c = result[0]\n",
        "        s = result[1]\n",
        "        s = s.detach()\n",
        "        s = s.detach()\n",
        "        c = c.cpu()\n",
        "        s = s.cpu()\n",
        "        c = c.numpy()\n",
        "        s = s.numpy()\n",
        "        c = INDEX_TO_CLASS[np.argmax(c)]\n",
        "        s = INDEX_TO_SUBCLASS[np.argmax(s)]\n",
        "\n",
        "        labels_stage.append(str((c, s)))\n",
        "        if s == 'harvest' or s == 'ripe':\n",
        "          class_id_stage.append(0)\n",
        "        else:\n",
        "          class_id_stage.append(2)\n",
        "\n",
        "        xyxy_final.append(read_xyxy[i][j])\n",
        "        masks_sam.append(sv.polygon_to_mask(np.array(read_polygons[i][j]), (image_rgb.shape[1], image_rgb.shape[0])))\n",
        "\n",
        "        '''\n",
        "        Classes\n",
        "        '''\n",
        "\n",
        "        xyxy = read_xyxy[i][j]\n",
        "        centre = (xyxy[0] + xyxy[2]) // 2, (xyxy[1] + xyxy[3]) // 2\n",
        "\n",
        "        min_key = None\n",
        "        min_dist = None\n",
        "        min_centre = None\n",
        "        for key in centres:\n",
        "          centre_compare = centres[key]\n",
        "          if (dist := math.sqrt(math.pow(abs(centre_compare[0] - centre[0]), 2) + math.pow(abs(centre_compare[1] - centre[1]), 2))) < 100:\n",
        "            if (min_key is not None and dist < min_dist) or (min_key is None):\n",
        "              min_key = key\n",
        "              min_dist = dist\n",
        "              min_centre = centre\n",
        "\n",
        "        if min_key is not None:\n",
        "          centres[min_key] = min_centre\n",
        "          if min_key not in areas.keys():\n",
        "            areas[min_key] = [None] * (i + 1)\n",
        "            forecasts[min_key] = [None] * (i + 1)\n",
        "          areas[min_key][-1] = geometry.Polygon(read_polygons[i][j]).area\n",
        "        else:\n",
        "          new_key = len(centres)\n",
        "          centres[new_key] = centre\n",
        "          areas[new_key] = [None] * (i + 1)\n",
        "          forecasts[new_key] = [None] * (i + 1)\n",
        "          areas[new_key][-1] = geometry.Polygon(read_polygons[i][j]).area\n",
        "\n",
        "        if min_key is not None:\n",
        "          labels_classes.append(f'{min_key}, {c}')\n",
        "          class_id_classes.append(min_key)\n",
        "          custom_colour_lookup_classes.append(min_key % len(colours))\n",
        "        else:\n",
        "          labels_classes.append(f'{new_key}, {c}')\n",
        "          class_id_classes.append(new_key)\n",
        "          custom_colour_lookup_classes.append(new_key % len(colours))\n",
        "\n",
        "      '''\n",
        "      Growth\n",
        "      '''\n",
        "\n",
        "      for key in areas:\n",
        "        if areas[key][-1] != None:\n",
        "          if sum(np.array(areas[key]) != None) > 3:\n",
        "            plant_areas = areas[key]\n",
        "\n",
        "            Y_df = dates.loc[:len(plant_areas) - 2].copy()\n",
        "            Y_df.loc[:, 'y'] = plant_areas[:-1]\n",
        "            Y_df['ds'] = pd.to_datetime(Y_df['ds'])\n",
        "\n",
        "            Y_df = Y_df.dropna()\n",
        "\n",
        "            A_df = dates.loc[:len(plant_areas) - 1].copy()\n",
        "            A_df.loc[:, 'y'] = plant_areas\n",
        "            A_df['ds'] = pd.to_datetime(A_df['ds'])\n",
        "\n",
        "            models_neural = [\n",
        "                Autoformer(\n",
        "                  h = 1,\n",
        "                  input_size = 2,\n",
        "                  hidden_size = 16,\n",
        "                  conv_hidden_size = 32,\n",
        "                  n_head = 2,\n",
        "                  loss = MAE(),\n",
        "                  scaler_type = 'robust',\n",
        "                  learning_rate = 0.006,\n",
        "                  max_steps = 100,\n",
        "                  val_check_steps = 50)\n",
        "            ]\n",
        "\n",
        "            nf = NeuralForecast(models = models_neural, freq = 'D')\n",
        "            nf.fit(df = Y_df)\n",
        "\n",
        "            Y_hat_neural_df = nf.predict()\n",
        "\n",
        "            Y_hat_neural_df = Y_hat_neural_df.reset_index()\n",
        "            Y_hat_neural_df = pd.concat([Y_df.rename(columns = {'y': 'Autoformer'}), Y_hat_neural_df])\n",
        "\n",
        "            forecasts[key][-1] = Y_hat_neural_df.iloc[-1, -1]\n",
        "\n",
        "            growth = A_df.iloc[-1, -1] > Y_hat_neural_df.iloc[-1, -1]\n",
        "\n",
        "            if growth:\n",
        "              labels_growth.append('Growing well!')\n",
        "              class_id_growth.append(0)\n",
        "            else:\n",
        "              labels_growth.append('Slow growth!')\n",
        "              class_id_growth.append(2)\n",
        "          else:\n",
        "            labels_growth.append('Growing...')\n",
        "            class_id_growth.append(1)\n",
        "\n",
        "      if READ_IMAGE:\n",
        "        if xyxy_final != []:\n",
        "          xyxy_final = np.array(xyxy_final)\n",
        "          masks_sam = np.array(masks_sam).astype(bool)\n",
        "          labels_stage = np.array(labels_stage)\n",
        "          class_id_stage = np.array(class_id_stage)\n",
        "\n",
        "          labels_growth = np.array(labels_growth)\n",
        "          class_id_growth = np.array(class_id_growth)\n",
        "\n",
        "          for m in ['sam']:\n",
        "            detections_stage = sv.Detections(\n",
        "                xyxy = xyxy_final,\n",
        "                mask = globals()[f'masks_{m}'],\n",
        "                class_id = class_id_stage\n",
        "            )\n",
        "\n",
        "            annotated_stage = mask_annotator.annotate(scene = image.copy(), detections = detections_stage, custom_color_lookup = class_id_stage)\n",
        "            combined_stage = box_annotator.annotate(scene = annotated_stage, detections = detections_stage, labels = labels_stage)\n",
        "            Image.fromarray(cv2.cvtColor(combined_stage, cv2.COLOR_BGR2RGB)).save(f'outputs/stage/{output_name}.png')\n",
        "\n",
        "            labels_classes = np.array(labels_classes)\n",
        "            class_id_classes = np.array(class_id_classes)\n",
        "            custom_colour_lookup_classes = np.array(custom_colour_lookup_classes)\n",
        "\n",
        "            detections_classes = sv.Detections(\n",
        "                xyxy = xyxy_final,\n",
        "                mask = globals()[f'masks_{m}'],\n",
        "                class_id = class_id_classes\n",
        "            )\n",
        "\n",
        "            annotated_classes = mask_annotator.annotate(scene = image.copy(), detections = detections_classes, custom_color_lookup = custom_colour_lookup_classes)\n",
        "            combined_classes = box_annotator.annotate(scene = annotated_classes, detections = detections_classes, labels = labels_classes)\n",
        "            Image.fromarray(cv2.cvtColor(combined_classes, cv2.COLOR_BGR2RGB)).save(f'outputs/classes/{output_name}.png')\n",
        "\n",
        "            detections_growth = sv.Detections(\n",
        "                xyxy = xyxy_final,\n",
        "                mask = globals()[f'masks_{m}'],\n",
        "                class_id = class_id_growth\n",
        "            )\n",
        "\n",
        "            annotated_growth = mask_annotator.annotate(scene = image.copy(), detections = detections_growth, custom_color_lookup = class_id_growth)\n",
        "            combined_growth = box_annotator.annotate(scene = annotated_growth, detections = detections_growth, labels = labels_growth)\n",
        "            Image.fromarray(cv2.cvtColor(combined_growth, cv2.COLOR_BGR2RGB)).save(f'outputs/growth/{output_name}.png')\n",
        "        else:\n",
        "          Image.fromarray(image_rgb).save(f'outputs/stage/{output_name}.png')\n",
        "          Image.fromarray(image_rgb).save(f'outputs/classes/{output_name}.png')\n",
        "          Image.fromarray(image_rgb).save(f'outputs/growth/{output_name}.png')\n",
        "    else:\n",
        "      if READ_IMAGE:\n",
        "        Image.fromarray(image_rgb).save(f'outputs/stage/{output_name}.png')\n",
        "        Image.fromarray(image_rgb).save(f'outputs/classes/{output_name}.png')\n",
        "        Image.fromarray(image_rgb).save(f'outputs/growth/{output_name}.png')"
      ],
      "metadata": {
        "id": "gkHJEDtUNwjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "read_outputs = {\n",
        "    'centres': centres,\n",
        "    'areas': areas,\n",
        "    'forecasts': forecasts\n",
        "}"
      ],
      "metadata": {
        "id": "TS1SLfav_icp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('read_outputs.json', mode='w') as f:\n",
        "    json.dump(read_outputs, f)"
      ],
      "metadata": {
        "id": "AYdC-zTk_xPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if READ_IMAGE and SAVE:\n",
        "  !zip -r outputs.zip outputs"
      ],
      "metadata": {
        "id": "MrcRpaJHu37Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Figures"
      ],
      "metadata": {
        "id": "oakAh4ZF_E-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "import plotly.graph_objs as go\n",
        "import plotly.io as pio"
      ],
      "metadata": {
        "id": "JsTzJ3Pw_IVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('figures', exist_ok = True)"
      ],
      "metadata": {
        "id": "CVOlbGAVA6KH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('read_outputs.json') as json_file:\n",
        "  read_outputs = json.load(json_file)"
      ],
      "metadata": {
        "id": "cuKuhSFo-zzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key in read_outputs['forecasts']:\n",
        "  areas = read_outputs['areas'][key]\n",
        "  forecasts = read_outputs['forecasts'][key]\n",
        "\n",
        "  Y_df = dates.loc[:len(areas) - 2].copy()\n",
        "  Y_df.loc[:, 'y'] = areas[:-1]\n",
        "  Y_df['ds'] = pd.to_datetime(Y_df['ds'])\n",
        "  Y_df = Y_df.dropna()\n",
        "\n",
        "  A_df = dates.loc[:len(forecasts) - 1].copy()\n",
        "  A_df.loc[:, 'y'] = forecasts\n",
        "  A_df['ds'] = pd.to_datetime(A_df['ds'])\n",
        "  A_df = A_df.dropna()\n",
        "\n",
        "  fig = go.Figure()\n",
        "\n",
        "  fig.add_trace(go.Scatter(x = Y_df.ds, y = Y_df['y'], name = 'Actual', line = dict(color = 'black')))\n",
        "  fig.add_trace(go.Scatter(x = A_df.ds, y = A_df['y'], name = 'Forecasts', line = dict(color = '#555555')))\n",
        "\n",
        "  fig.update_layout(title = f'Actual vs Forecasted Surface Areas', xaxis_title = 'Date', yaxis_title = 'Surface Area', legend = dict(x = 1, y = 1))\n",
        "\n",
        "  pio.write_html(fig, f'figures/{key}.html')\n",
        "\n",
        "  fig.show()"
      ],
      "metadata": {
        "id": "3jBzUX55-1ss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if READ_IMAGE and SAVE:\n",
        "  !zip -r figures.zip figures"
      ],
      "metadata": {
        "id": "jN3u_E5VO5Jc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}